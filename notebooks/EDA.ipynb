{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains Exploratory Data Analysis of the Data set provided by Dr. Hong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Packages\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>contributors</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Perspective</th>\n",
       "      <th>Issuereport</th>\n",
       "      <th>Issuecritique</th>\n",
       "      <th>Need</th>\n",
       "      <th>extracted_place</th>\n",
       "      <th>state_of_tweet</th>\n",
       "      <th>user_coordinates</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Oct 01 00:00:06 +0000 2017</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>RT @NIVIsa4031: .@fema their response to Puert...</td>\n",
       "      <td>{'id': 852896725597659137, 'id_str': '85289672...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>critique</td>\n",
       "      <td>local</td>\n",
       "      <td>damage-need</td>\n",
       "      <td>government</td>\n",
       "      <td>other</td>\n",
       "      <td>Alabama, USA</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>[-86.75026, 32.75041]</td>\n",
       "      <td>-86.75026</td>\n",
       "      <td>32.75041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Oct 01 02:04:33 +0000 2017</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>RT @Visacca: I love you, #PuertoRico.ðŸŒ¹</td>\n",
       "      <td>{'id': 771511754, 'id_str': '771511754', 'name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>report</td>\n",
       "      <td>local</td>\n",
       "      <td>damage-need</td>\n",
       "      <td>100</td>\n",
       "      <td>other</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>[-86.80249, 33.52066]</td>\n",
       "      <td>-86.80249</td>\n",
       "      <td>33.52066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Oct 01 02:36:59 +0000 2017</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>Ok all of the Puerto Rican folks flowing into ...</td>\n",
       "      <td>{'id': 832308689902120960, 'id_str': '83230868...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>report</td>\n",
       "      <td>local</td>\n",
       "      <td>societal-aid</td>\n",
       "      <td>100</td>\n",
       "      <td>other</td>\n",
       "      <td>Melbourne, FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-80.60811, 28.08363]</td>\n",
       "      <td>-80.60811</td>\n",
       "      <td>28.08363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Oct 01 12:22:31 +0000 2017</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>RT @reedfrich: How Trump's xenophobic immigrat...</td>\n",
       "      <td>{'id': 18104303, 'id_str': '18104303', 'name':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>critique</td>\n",
       "      <td>local</td>\n",
       "      <td>societal-aid</td>\n",
       "      <td>government</td>\n",
       "      <td>other</td>\n",
       "      <td>Tampa, Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-82.45843, 27.94752]</td>\n",
       "      <td>-82.45843</td>\n",
       "      <td>27.94752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Oct 01 12:43:24 +0000 2017</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>9.140000e+17</td>\n",
       "      <td>RT @RobinRespaut: Cruise ship arrived in San J...</td>\n",
       "      <td>{'id': 24016008, 'id_str': '24016008', 'name':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>report</td>\n",
       "      <td>local</td>\n",
       "      <td>societal-aid</td>\n",
       "      <td>100</td>\n",
       "      <td>physiological</td>\n",
       "      <td>Atlanta, Florida, Kgn Jamaica</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[-82.5001, 28.75054]</td>\n",
       "      <td>-82.50010</td>\n",
       "      <td>28.75054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at            id        id_str  \\\n",
       "0  Sun Oct 01 00:00:06 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "1  Sun Oct 01 02:04:33 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "2  Sun Oct 01 02:36:59 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "3  Sun Oct 01 12:22:31 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "4  Sun Oct 01 12:43:24 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @NIVIsa4031: .@fema their response to Puert...   \n",
       "1             RT @Visacca: I love you, #PuertoRico.ðŸŒ¹   \n",
       "2  Ok all of the Puerto Rican folks flowing into ...   \n",
       "3  RT @reedfrich: How Trump's xenophobic immigrat...   \n",
       "4  RT @RobinRespaut: Cruise ship arrived in San J...   \n",
       "\n",
       "                                                user  geo coordinates place  \\\n",
       "0  {'id': 852896725597659137, 'id_str': '85289672...  NaN         NaN   NaN   \n",
       "1  {'id': 771511754, 'id_str': '771511754', 'name...  NaN         NaN   NaN   \n",
       "2  {'id': 832308689902120960, 'id_str': '83230868...  NaN         NaN   NaN   \n",
       "3  {'id': 18104303, 'id_str': '18104303', 'name':...  NaN         NaN   NaN   \n",
       "4  {'id': 24016008, 'id_str': '24016008', 'name':...  NaN         NaN   NaN   \n",
       "\n",
       "   contributors lang  ...    Frames Perspective   Issuereport Issuecritique  \\\n",
       "0           NaN   en  ...  critique       local   damage-need    government   \n",
       "1           NaN   en  ...    report       local   damage-need           100   \n",
       "2           NaN   en  ...    report       local  societal-aid           100   \n",
       "3           NaN   en  ...  critique       local  societal-aid    government   \n",
       "4           NaN   en  ...    report       local  societal-aid           100   \n",
       "\n",
       "            Need                extracted_place state_of_tweet  \\\n",
       "0          other                   Alabama, USA        Alabama   \n",
       "1          other                 Birmingham, AL        Alabama   \n",
       "2          other                  Melbourne, FL        Florida   \n",
       "3          other                 Tampa, Florida        Florida   \n",
       "4  physiological  Atlanta, Florida, Kgn Jamaica        Florida   \n",
       "\n",
       "        user_coordinates longitude  latitude  \n",
       "0  [-86.75026, 32.75041] -86.75026  32.75041  \n",
       "1  [-86.80249, 33.52066] -86.80249  33.52066  \n",
       "2  [-80.60811, 28.08363] -80.60811  28.08363  \n",
       "3  [-82.45843, 27.94752] -82.45843  27.94752  \n",
       "4   [-82.5001, 28.75054] -82.50010  28.75054  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataframe\n",
    "\n",
    "df = pd.read_csv('/home/reu24mandaloju/Project_INFO_5709/data/Final_Immigrants_geolocation_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at              object\n",
       "id                     float64\n",
       "id_str                 float64\n",
       "text                    object\n",
       "user                    object\n",
       "geo                     object\n",
       "coordinates             object\n",
       "place                   object\n",
       "contributors           float64\n",
       "lang                    object\n",
       "timestamp_ms           float64\n",
       "matching_rules          object\n",
       "extended_entities       object\n",
       "cleaned_text            object\n",
       "mentioned_countries     object\n",
       "Frames                  object\n",
       "Perspective             object\n",
       "Issuereport             object\n",
       "Issuecritique           object\n",
       "Need                    object\n",
       "extracted_place         object\n",
       "state_of_tweet          object\n",
       "user_coordinates        object\n",
       "longitude              float64\n",
       "latitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding hte data types of the columns\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                           created_at            id        id_str  \\\n",
       "0     Sun Oct 01 00:00:06 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "1     Sun Oct 01 02:04:33 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "2     Sun Oct 01 02:36:59 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "3     Sun Oct 01 12:22:31 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "4     Sun Oct 01 12:43:24 +0000 2017  9.140000e+17  9.140000e+17   \n",
       "...                              ...           ...           ...   \n",
       "2563  Fri Sep 01 18:27:17 +0000 2017  9.040000e+17  9.040000e+17   \n",
       "2564  Fri Sep 01 23:09:28 +0000 2017  9.040000e+17  9.040000e+17   \n",
       "2565  Fri Sep 01 23:15:41 +0000 2017  9.040000e+17  9.040000e+17   \n",
       "2566  Sat Sep 02 04:43:31 +0000 2017  9.040000e+17  9.040000e+17   \n",
       "2567  Sat Sep 02 11:03:27 +0000 2017  9.040000e+17  9.040000e+17   \n",
       "\n",
       "                                                   text  \\\n",
       "0     RT @NIVIsa4031: .@fema their response to Puert...   \n",
       "1                RT @Visacca: I love you, #PuertoRico.ðŸŒ¹   \n",
       "2     Ok all of the Puerto Rican folks flowing into ...   \n",
       "3     RT @reedfrich: How Trump's xenophobic immigrat...   \n",
       "4     RT @RobinRespaut: Cruise ship arrived in San J...   \n",
       "...                                                 ...   \n",
       "2563  Immigrants will suffer the worst after Hurrica...   \n",
       "2564  Undocumented immigrants told us about their fe...   \n",
       "2565  Due to hurricane Harvey there is no real good ...   \n",
       "2566  DACA paramedic makes sure many others will con...   \n",
       "2567  @CNN @CNNPolitics go stage another refugee res...   \n",
       "\n",
       "                                                   user  geo coordinates  \\\n",
       "0     {'id': 852896725597659137, 'id_str': '85289672...  NaN         NaN   \n",
       "1     {'id': 771511754, 'id_str': '771511754', 'name...  NaN         NaN   \n",
       "2     {'id': 832308689902120960, 'id_str': '83230868...  NaN         NaN   \n",
       "3     {'id': 18104303, 'id_str': '18104303', 'name':...  NaN         NaN   \n",
       "4     {'id': 24016008, 'id_str': '24016008', 'name':...  NaN         NaN   \n",
       "...                                                 ...  ...         ...   \n",
       "2563  {'id': 727933551526748161, 'id_str': '72793355...  NaN         NaN   \n",
       "2564  {'id': 48088050, 'id_str': '48088050', 'name':...  NaN         NaN   \n",
       "2565  {'id': 29513395, 'id_str': '29513395', 'name':...  NaN         NaN   \n",
       "2566  {'id': 887671540430647296, 'id_str': '88767154...  NaN         NaN   \n",
       "2567  {'id': 340334747, 'id_str': '340334747', 'name...  NaN         NaN   \n",
       "\n",
       "                                                  place  contributors lang  \\\n",
       "0                                                   NaN           NaN   en   \n",
       "1                                                   NaN           NaN   en   \n",
       "2                                                   NaN           NaN   en   \n",
       "3                                                   NaN           NaN   en   \n",
       "4                                                   NaN           NaN   en   \n",
       "...                                                 ...           ...  ...   \n",
       "2563  {'id': '04cb31bae3b3af93', 'url': 'https://api...           NaN   en   \n",
       "2564  {'id': '1703b859c254a0f9', 'url': 'https://api...           NaN   en   \n",
       "2565  {'id': 'fa8f8f24dc772cc0', 'url': 'https://api...           NaN   en   \n",
       "2566  {'id': '481021182030dbe6', 'url': 'https://api...           NaN   en   \n",
       "2567  {'id': '4caafbe771809878', 'url': 'https://api...           NaN   en   \n",
       "\n",
       "      ...    Frames Perspective   Issuereport Issuecritique           Need  \\\n",
       "0     ...  critique       local   damage-need    government          other   \n",
       "1     ...    report       local   damage-need           100          other   \n",
       "2     ...    report       local  societal-aid           100          other   \n",
       "3     ...  critique       local  societal-aid    government          other   \n",
       "4     ...    report       local  societal-aid           100  physiological   \n",
       "...   ...       ...         ...           ...           ...            ...   \n",
       "2563  ...  critique       local  societal-aid           100  physiological   \n",
       "2564  ...  critique       local  societal-aid           100  physiological   \n",
       "2565  ...  critique       local   damage-need    government          other   \n",
       "2566  ...    report       local  societal-aid           100  physiological   \n",
       "2567  ...    report       local   damage-need           100  physiological   \n",
       "\n",
       "                     extracted_place state_of_tweet       user_coordinates  \\\n",
       "0                       Alabama, USA        Alabama  [-86.75026, 32.75041]   \n",
       "1                     Birmingham, AL        Alabama  [-86.80249, 33.52066]   \n",
       "2                      Melbourne, FL        Florida  [-80.60811, 28.08363]   \n",
       "3                     Tampa, Florida        Florida  [-82.45843, 27.94752]   \n",
       "4      Atlanta, Florida, Kgn Jamaica        Florida   [-82.5001, 28.75054]   \n",
       "...                              ...            ...                    ...   \n",
       "2563                           Miami           Iowa  [-80.19366, 25.77427]   \n",
       "2564                             NaN            NaN                    NaN   \n",
       "2565                            Here            NaN                    NaN   \n",
       "2566                    McGregor, FL        Florida  [-81.91453, 26.56091]   \n",
       "2567   Guess? USA all u need 2 know!        Alabama                    NaN   \n",
       "\n",
       "     longitude  latitude  \n",
       "0    -86.75026  32.75041  \n",
       "1    -86.80249  33.52066  \n",
       "2    -80.60811  28.08363  \n",
       "3    -82.45843  27.94752  \n",
       "4    -82.50010  28.75054  \n",
       "...        ...       ...  \n",
       "2563 -80.19366  25.77427  \n",
       "2564       NaN       NaN  \n",
       "2565       NaN       NaN  \n",
       "2566 -81.91453  26.56091  \n",
       "2567       NaN       NaN  \n",
       "\n",
       "[2568 rows x 25 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the statistics of the data\n",
    "\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2568, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'user', 'geo', 'coordinates',\n",
       "       'place', 'contributors', 'lang', 'timestamp_ms', 'matching_rules',\n",
       "       'extended_entities', 'cleaned_text', 'mentioned_countries', 'Frames',\n",
       "       'Perspective', 'Issuereport', 'Issuecritique', 'Need',\n",
       "       'extracted_place', 'state_of_tweet', 'user_coordinates', 'longitude',\n",
       "       'latitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the columns of the data\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                0\n",
       "id                        0\n",
       "id_str                    0\n",
       "text                      0\n",
       "user                      0\n",
       "geo                    2560\n",
       "coordinates            2560\n",
       "place                  2370\n",
       "contributors           2568\n",
       "lang                      0\n",
       "timestamp_ms              0\n",
       "matching_rules            0\n",
       "extended_entities      2391\n",
       "cleaned_text              2\n",
       "mentioned_countries    2116\n",
       "Frames                    0\n",
       "Perspective               0\n",
       "Issuereport               0\n",
       "Issuecritique             0\n",
       "Need                      0\n",
       "extracted_place          28\n",
       "state_of_tweet           32\n",
       "user_coordinates         38\n",
       "longitude                38\n",
       "latitude                 38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the null values in the data\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2568, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the columns which have the most null values\n",
    "\n",
    "df = df.drop(columns=['geo','coordinates','place','contributors','extended_entities','mentioned_countries'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['critique' 'report' 'other']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding unique values of a column.\n",
    "\n",
    "unique_values = df['Frames'].unique()\n",
    "print(unique_values)\n",
    "len(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'cleaned_text' or coordinates are missing\n",
    "df = df.dropna(subset=['cleaned_text', 'longitude', 'latitude'])\n",
    "\n",
    "# Removing columns with only one unique value as this doesn't contribute to anything\n",
    "df = df.drop(columns= ['lang'])\n",
    "\n",
    "# Removing redudant columns - we have latitude and longitude\n",
    "df = df.drop(columns= ['user_coordinates'])\n",
    "\n",
    "# dropping 'id' and 'id_str' as both of them have only 19 unique values\n",
    "# This could be due to many tweet IDs got truncated or duplicated when the data was processed\n",
    "# or exported to scientific notation rounding.\n",
    "df = df.drop(columns= ['id','id_str'])\n",
    "\n",
    "\n",
    "# dropping 'timestamp_ms' as it has only 2 unique value and doesn't make any sense\n",
    "# This could have got duplicated as well\n",
    "df = df.drop(columns=['timestamp_ms'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at         0\n",
       "text               0\n",
       "user               0\n",
       "matching_rules     0\n",
       "cleaned_text       0\n",
       "Frames             0\n",
       "Perspective        0\n",
       "Issuereport        0\n",
       "Issuecritique      0\n",
       "Need               0\n",
       "extracted_place    0\n",
       "state_of_tweet     0\n",
       "longitude          0\n",
       "latitude           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1003191/1832539936.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['created_at'] = pd.to_datetime(df['created_at'])\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Extract date and day\n",
    "df['Tweet_date'] = df['created_at'].dt.date\n",
    "df['Tweet_day'] = df['created_at'].dt.day_name()\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(columns=['created_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'user', 'matching_rules', 'cleaned_text', 'Frames',\n",
       "       'Perspective', 'Issuereport', 'Issuecritique', 'Need',\n",
       "       'extracted_place', 'state_of_tweet', 'longitude', 'latitude',\n",
       "       'Tweet_date', 'Tweet_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns again\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#print(json.dumps(df['user'].iloc[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting useful information from the 'user' column\n",
    "\n",
    "import ast\n",
    "\n",
    "# Step 1: Parse the stringified Python dict safely\n",
    "df['user'] = df['user'].apply(ast.literal_eval)\n",
    "\n",
    "# Step 2: Normalize\n",
    "user_df = pd.json_normalize(df['user'])\n",
    "\n",
    "# Step 3: Extract desired columns (adding NaNs if missing)\n",
    "cols_to_extract = [\n",
    "    'id', 'screen_name', 'followers_count',\n",
    "    'friends_count', 'statuses_count', 'created_at',\n",
    "    'verified', 'description'\n",
    "]\n",
    "\n",
    "for col in cols_to_extract:\n",
    "    if col not in user_df.columns:\n",
    "        user_df[col] = pd.NA\n",
    "\n",
    "user_df = user_df[cols_to_extract].rename(columns={\n",
    "    'id': 'user_id',\n",
    "    'created_at': 'user_created_at'\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2528, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the shape of the user_df\n",
    "\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              0\n",
       "screen_name          0\n",
       "followers_count      0\n",
       "friends_count        0\n",
       "statuses_count       0\n",
       "user_created_at      0\n",
       "verified             0\n",
       "description        168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values of the user_df\n",
    "\n",
    "user_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset both indexes to ensure row-wise alignment\n",
    "df = df.reset_index(drop=True)\n",
    "user_df = user_df.reset_index(drop=True)\n",
    "\n",
    "# Then concat safely\n",
    "df = pd.concat([df, user_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'user', 'matching_rules', 'cleaned_text', 'Frames',\n",
       "       'Perspective', 'Issuereport', 'Issuecritique', 'Need',\n",
       "       'extracted_place', 'state_of_tweet', 'longitude', 'latitude',\n",
       "       'Tweet_date', 'Tweet_day', 'user_id', 'screen_name', 'followers_count',\n",
       "       'friends_count', 'statuses_count', 'user_created_at', 'verified',\n",
       "       'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the columns again\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['created_at'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1003191/3613844146.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['user_created_at'] = pd.to_datetime(df['user_created_at'])\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "df['user_created_at'] = pd.to_datetime(df['user_created_at'])\n",
    "\n",
    "# Extract date and day\n",
    "df['User_Created_date'] = df['user_created_at'].dt.date\n",
    "df['User_Created_day'] = df['user_created_at'].dt.day_name()\n",
    "\n",
    "# Drop the original column\n",
    "df = df.drop(columns=['user_created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['User_Created_day'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null values in the description column with 'NA'\n",
    "\n",
    "df['description'] = df['description'].fillna('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "user                 0\n",
       "matching_rules       0\n",
       "cleaned_text         0\n",
       "Frames               0\n",
       "Perspective          0\n",
       "Issuereport          0\n",
       "Issuecritique        0\n",
       "Need                 0\n",
       "extracted_place      0\n",
       "state_of_tweet       0\n",
       "longitude            0\n",
       "latitude             0\n",
       "Tweet_date           0\n",
       "Tweet_day            0\n",
       "user_id              0\n",
       "screen_name          0\n",
       "followers_count      0\n",
       "friends_count        0\n",
       "statuses_count       0\n",
       "verified             0\n",
       "description          0\n",
       "User_Created_date    0\n",
       "User_Created_day     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final check of the null values in the data \n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some irrelevant columns for visualizaton using tableau\n",
    "\n",
    "df = df.drop(columns=['text','user', 'matching_rules','cleaned_text','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('/home/reu24mandaloju/Project_INFO_5709/data/cleaned_immigrant_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
